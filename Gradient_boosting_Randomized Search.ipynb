{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Wall time: 5min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load csv Data as pandas dataframe\n",
    "df = pd.read_csv('Intermediate_data\\Trimmed.csv',\n",
    "                 parse_dates=['earliest_cr_line',\n",
    "                              'issue_d', 'last_pymnt_d',\n",
    "                              'next_pymnt_d', 'last_credit_pull_d'])\n",
    "\n",
    "df['history'] = (df.issue_d - df.earliest_cr_line).dt.days\n",
    "\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns and the columns that leak the\n",
    "# information. For example, non-zero value in\n",
    "# 'collection recovery fee' column already mean\n",
    "# that the loan is default. Also remove some columns that have\n",
    "# very little or zero predictive power\n",
    "\n",
    "df.drop(['last_pymnt_amnt', 'collection_recovery_fee',\n",
    "         'recoveries', 'out_prncp_inv', 'out_prncp',\n",
    "         'total_rec_prncp', 'int_rate', 'total_pymnt',\n",
    "         'total_pymnt_inv', 'total_rec_late_fee',\n",
    "         'total_rec_int', 'emp_title', 'debt_settlement_flag',\n",
    "         'addr_state', 'purpose', 'delinq_amnt',\n",
    "         'hardship_flag', 'pymnt_plan', 'collections_12_mths_ex_med',\n",
    "         'chargeoff_within_12_mths', 'acc_now_delinq',\n",
    "         'earliest_cr_line', 'issue_d', 'last_pymnt_d',\n",
    "         'next_pymnt_d', 'last_credit_pull_d'],\n",
    "        axis=1, inplace=True)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Some columns are categorical. I converted\n",
    "# them to categorical dummies (0 or 1)\n",
    "\n",
    "cate_list = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "\n",
    "df_cate = df[cate_list]\n",
    "\n",
    "df_cat_dum = pd.get_dummies(df_cate, drop_first=True)\n",
    "df_cat_dum.drop('loan_status_Late/Charged Off', axis=1, inplace=True)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create the subset of numerical columns.\n",
    "\n",
    "df_num_col = df.dtypes[df.dtypes == 'float64']\n",
    "\n",
    "df_num = df[list(df_num_col.index)]\n",
    "\n",
    "y = 1 - pd.get_dummies(df.loan_status, drop_first=True)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Some of the numerical columns contain missing values. I\n",
    "# filled the missing values using\n",
    "# the mean value of the column.\n",
    "\n",
    "for col in df_num.columns:\n",
    "    df_num[col].fillna(df_num[col].mean(), inplace=True)\n",
    "\n",
    "# Combine categorical and numerical columns\n",
    "df_com = pd.concat([df_num, df_cat_dum, y], axis=1)\n",
    "\n",
    "# The majority of the data is contains non-default loans.\n",
    "# Making equal population is\n",
    "# essential to make an unbiased model.\n",
    "\n",
    "df0 = df_com[df_com['Late/Charged Off'] == 0]\n",
    "df1 = df_com[df_com['Late/Charged Off'] == 1].sample(n=df0.shape[0])\n",
    "\n",
    "# Combine both subsample of default or non-default loans\n",
    "df_combined = pd.concat([df0, df1], axis=0)\n",
    "df_com = df_combined.sample(frac=1.0)\n",
    "\n",
    "y = df_com['Late/Charged Off']\n",
    "X = df_com.drop(['Late/Charged Off'], axis=1).values\n",
    "\n",
    "# Scale the data to their standard values.\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized search best parameters: {'n_estimators': 1505, 'min_weight_fraction_leaf': 0.05, 'min_samples_split': 1505, 'min_samples_leaf': 302, 'max_features': 0.45000000000000007, 'max_depth': 1002}\n",
      "Best score is 0.6694960822050899\n"
     ]
    }
   ],
   "source": [
    "# Create parameter grid to perform randomized search\n",
    "param_grid = {'max_features': np.arange(0.05, 0.5, 0.1),\n",
    "              'n_estimators': np.arange(5, 2000, 500),\n",
    "              'min_samples_leaf': np.arange(2, 1000, 300),\n",
    "              'min_samples_split': np.arange(5, 2000, 500),\n",
    "              'max_depth': np.arange(2, 2000, 500),\n",
    "              'min_weight_fraction_leaf': np.arange(0.05, 0.3, 0.1)}\n",
    "\n",
    "# Make a randomized search model\n",
    "random_search = RandomizedSearchCV(GradientBoostingClassifier(),\n",
    "                                   param_distributions=param_grid,\n",
    "                                   cv=3, refit=True, n_jobs=-2,\n",
    "                                   random_state=77)\n",
    "\n",
    "# Perform a fit\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Randomized search best parameters: {}\".\n",
    "      format(random_search.best_params_))\n",
    "print(\"Best score is {}\".format(random_search.best_score_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

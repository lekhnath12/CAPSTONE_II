{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lnp2\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_curve, confusion_matrix, roc_auc_score\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "df = pd.read_csv('Intermediate_data\\Trimmed.csv', \n",
    "                 parse_dates = ['earliest_cr_line', 'issue_d', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d'])\n",
    "\n",
    "df['history'] = (df.issue_d - df.earliest_cr_line).dt.days \n",
    "\n",
    "df.drop(['Unnamed: 0'], axis = 1, inplace =  True)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['last_pymnt_amnt', 'collection_recovery_fee', 'recoveries', 'out_prncp_inv', \n",
    "         'out_prncp', 'total_rec_prncp', 'int_rate', 'total_pymnt', 'total_pymnt_inv',\n",
    "         'total_rec_late_fee', 'total_rec_int', 'emp_title', 'debt_settlement_flag', \n",
    "         'addr_state', 'purpose', 'delinq_amnt', 'hardship_flag', 'pymnt_plan', \n",
    "         'collections_12_mths_ex_med', 'chargeoff_within_12_mths', 'acc_now_delinq', \n",
    "         'earliest_cr_line', 'issue_d', 'last_pymnt_d', 'next_pymnt_d', \n",
    "         'last_credit_pull_d'],\n",
    "         axis = 1, inplace = True)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_list = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "\n",
    "df_cate = df[cate_list]\n",
    "\n",
    "df_cat_dum = pd.get_dummies(df_cate, drop_first = True)\n",
    "df_cat_dum.drop('loan_status_Late/Charged Off', axis = 1, inplace = True)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_col = df.dtypes[df.dtypes == 'float64']\n",
    "\n",
    "df_num = df[list(df_num_col.index)]\n",
    "\n",
    "y = 1 -pd.get_dummies(df.loan_status, drop_first = True)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_num.columns:\n",
    "    df_num[col].fillna(df_num[col].mean(), inplace = True)\n",
    "    \n",
    "df_com = pd.concat([df_num, df_cat_dum, y], axis = 1)\n",
    "\n",
    "df0 = df_com[df_com['Late/Charged Off'] == 0]\n",
    "df1 = df_com[df_com['Late/Charged Off'] == 1].sample(n = df0.shape[0])  \n",
    "\n",
    "df_combined = pd.concat([df0, df1], axis = 0)\n",
    "df_com = df_combined.sample(frac = 1.0)\n",
    "\n",
    "y = df_com['Late/Charged Off']\n",
    "X = df_com.drop(['Late/Charged Off'], axis = 1).values\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled, y, test_size=0.5, random_state = 77)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test \n",
    "model = GradientBoostingClassifier(verbose = 1,\n",
    "                                       random_state  = 77)\n",
    "    \n",
    "model.fit(X_train, y_train)\n",
    "score = model.score(X_test, y_test)\n",
    "parm_val = {}\n",
    "    \n",
    "fw = open(\"GB_FIT_detail.txt\", 'a')\n",
    "fw.write(str(datetime.now()) + '\\t' + str(parm_val)+'\\t'+ str(score)+ '\\n')\n",
    "\n",
    "fw.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-06 10:01:28.609020 0.6558384971093979\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_features': np.arange(0.05,0.5, 0.02), 'n_estimators': np.arange(5,20000,1), \n",
    "             'min_samples_leaf': np.arange(2, 10000, 5), 'min_samples_split': np.arange(1, 10000, 5),\n",
    "             'max_depth': np.arange(2, 10000, 1), 'learning_rate': np.arange(0.01, 0.5, 0.05),\n",
    "             'min_weight_fraction_leaf': np.arange(0,0.1, 0.02)\n",
    "             }\n",
    "\n",
    "\n",
    "#fw = open(\"GB_FIT_detail.txt\",\"w\")\n",
    "#fw.write('Datetime \\t parameters \\t Score \\n')\n",
    "#fw.close\n",
    "\n",
    "i = 0\n",
    "while i < 2000:\n",
    "    parm_val = dict()\n",
    "    for keys, values in param_grid.items():\n",
    "        parm_val[keys] = np.random.choice(values)\n",
    "    \n",
    "    model = GradientBoostingClassifier(max_features = parm_val['max_features'], \n",
    "                                       n_estimators = parm_val['n_estimators'],\n",
    "                                       min_samples_leaf = parm_val['min_samples_leaf'],\n",
    "                                       max_depth = parm_val['max_depth'],\n",
    "                                       min_weight_fraction_leaf = parm_val['min_weight_fraction_leaf'], \n",
    "                                       min_samples_split = parm_val['min_samples_split'],\n",
    "                                       learning_rate = parm_val['learning_rate'],\n",
    "                                       random_state  = 77)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    fw = open(\"GB_FIT_detail.txt\", 'a')\n",
    "    fw.write(str(datetime.now()) + '\\t' + str(parm_val)+'\\t'+ str(score)+ '\\n')\n",
    "    fw.close()\n",
    "    \n",
    "    print(datetime.now(), score)\n",
    "    \n",
    "    i = i+1\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "read_score = pd.read_csv('GB_FIT_detail.txt', sep = '\\t')\n",
    "\n",
    "read_score.sort_values(by = ' Score ', inplace = True, ascending = False)\n",
    "\n",
    "parm_val = eval(read_score.iloc[0,1])\n",
    "\n",
    "model = GradientBoostingClassifier(max_features = parm_val['max_features'], \n",
    "                                   n_estimators = parm_val['n_estimators'],\n",
    "                                   min_samples_leaf = parm_val['min_samples_leaf'],\n",
    "                                   max_depth = parm_val['max_depth'],\n",
    "                                   min_weight_fraction_leaf = parm_val['min_weight_fraction_leaf'], \n",
    "                                   min_samples_split = parm_val['min_samples_split'],\n",
    "                                   learning_rate = parm_val['learning_rate'],\n",
    "                                   verbose = 0,\n",
    "                                   random_state = 77)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "score = model.score(X_test, y_test)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred,  target_names = ['paid', 'not-paid']))\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr,tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, 'r',label = 'Gradient Boosting')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(model, 'Grad_boosting.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_list = list(df_com.drop(['Late/Charged Off'], axis = 1).columns)\n",
    "\n",
    "feat = model.feature_importances_\n",
    "feat = pd.DataFrame(data = feat, index = col_list, columns= ['Feat_imp'] )\n",
    "feat.sort_values(by = 'Feat_imp', ascending = False, inplace = True)\n",
    "feat.to_csv('Intermediate_data\\Feature_imp_GB.csv')\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
